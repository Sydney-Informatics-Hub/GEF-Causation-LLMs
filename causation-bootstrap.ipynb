{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53664cb5-36ef-4fd5-8609-573fc16c8b05",
   "metadata": {},
   "source": [
    "# Causation (Bootstrap: Reprompting)\n",
    "\n",
    "In this notebook, you can bootstrap CoT examples using ChatGPT.<br>\n",
    "\n",
    "*Please note: This is a partial implementation of the Reprompting paper (see below), where the second portion is skipped for the moment as the metric for convergence is unclear and require a bit of further testing. However, the first bootstrapping process is implemented here.*\n",
    "\n",
    "ðŸ‘¼ At the end of the notebook, you will be able to download a `.toml` file which you can use with the `causation-cotsc` notebook.\n",
    "\n",
    "ðŸ‘¼ This notebook alleviates the human labour required for annotating CoT examples. This means you can quickly generate the reasoning and examine them. However, class definitions and a labelled dataset is still required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90157b3d-19df-479d-9da8-ebcaa4ea6396",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OpenAI Privacy Policy\n",
    "This notebook uses OpenAI's API, meaning that your data will be sent to the OpenAI servers.\n",
    "\n",
    "For concerns about how your data will be handled, please read through the Privacy Policy [here](https://openai.com/policies/api-data-usage-policies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832eff9b-c18c-4dd4-9414-5da1d1d24ccd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Paper: Reprompting (expand to read)\n",
    "Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling: https://arxiv.org/abs/2305.09993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb4b67-aedf-4b13-929d-d64e24a48798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(src='https://arxiv.org/pdf/2305.09993.pdf', width=1600, height=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251151b-bc3a-437f-871e-fc31950e0ba3",
   "metadata": {},
   "source": [
    "## 1. Enter your OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9752d3-4d7a-4947-b648-e390b6e4782a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import openai_apikey_input\n",
    "openai_apikey_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd953b7-591f-47f7-8ec3-7ecc1cc33b9c",
   "metadata": {},
   "source": [
    "## 2. Upload your instruction toml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafc69e-cc11-4822-9dcf-9ebf091dab72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import fileuploader\n",
    "\n",
    "finput, instrs = fileuploader('.toml')\n",
    "finput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ca113-35ba-427d-a12d-b50bef91346d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert instrs.get('data'), \"Did you upload your CoT definitions?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663de685-9705-4cea-b870-0bab5852394b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Build prompt for bootstrapping (No user interaction required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642c4e0-3bca-417d-aa37-ad38d266ba53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import toml\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# response schema\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"reason\", description=\"The reasoning for the classification in a logical step by step manner.\"),\n",
    "    ResponseSchema(name=\"answer\", description=\"The classification\"),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# load instructions from toml\n",
    "path = instrs.get('data')\n",
    "data = toml.load(path)\n",
    "\n",
    "# system messages\n",
    "prefix = data.pop('PREFIX', None)\n",
    "prefix = prefix.get('instruction') if prefix is not None else None\n",
    "\n",
    "instructions = list()\n",
    "classes = list(data.keys())\n",
    "for clazz in classes:\n",
    "    instruction = data.get(clazz).get('instruction')\n",
    "    instruction = f\"<class>\\n{clazz}: {instruction}</class>\"\n",
    "    instructions.append(instruction)\n",
    "\n",
    "sys_template = prefix + \"\\n\\n\" + f\"\"\"\n",
    "The following are {len(classes)} classes with a description of each. \n",
    "These are XML delimited with <class> tags in the format: <class> Class: Description </class>.\n",
    "Please classify each 'query' as one of the {len(classes)} classes.\\n\\n\"\"\" + '\\n'.join(instructions) + \"\\n\\n\"\n",
    "\n",
    "sys_prompt = PromptTemplate(template=sys_template, input_variables=[])\n",
    "bootstrap_sys = SystemMessagePromptTemplate(prompt=sys_prompt)\n",
    "\n",
    "\n",
    "human_template = r\"\"\"\n",
    "{format_instructions}\n",
    "\n",
    "Let's think logically step by step and make sure you provide your best answer. In your reasoning say why it is NOT the other classes.\n",
    "Query: {query}\"\"\"\n",
    "\n",
    "human_prompt = PromptTemplate(\n",
    "    template=human_template,\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instructions': output_parser.get_format_instructions()},\n",
    ")\n",
    "bootstrap_human = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "bootstrap_prompt = ChatPromptTemplate.from_messages([bootstrap_sys, bootstrap_human])\n",
    "\n",
    "\"Bootstrap prompt created. Please continue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7743b58-5632-4807-ab13-dbeae4233f02",
   "metadata": {},
   "source": [
    "## 4. Define Bootstrapping (No user interaction required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddabe53-be50-4d79-a86a-2866e8ede4e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)\n",
    "f\"Your model name is: {chat_model.model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093dfa9-aeba-43c7-89f0-994da6a85703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing\n",
    "import re, json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ReasonAnswerPair:\n",
    "    r: str\n",
    "    a: str\n",
    "\n",
    "def parse(output: str) -> ReasonAnswerPair:\n",
    "    try:\n",
    "        if output.startswith('{') and output.strip().endswith('}'):\n",
    "            json_string = output\n",
    "        else:\n",
    "            json_string = re.search(r'```json\\n(.*?)```', output, re.DOTALL).group(1)\n",
    "        j = json.loads(json_string)\n",
    "        return ReasonAnswerPair(r=j.get('reason'), a=j.get('answer'))\n",
    "    except:\n",
    "        return ReasonAnswerPair(r=output, a='')\n",
    "    \n",
    "\"Postprocessing parser created. Please continue.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f88ea-1b46-4b0a-bf65-e8e37c334f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\" Bootstrapping\n",
    "\n",
    "Use zero-shot GPT to obtain a bunch of CoTRecipes.\n",
    "Input: bunch of queries and associated answer.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CoTRecipe:   \n",
    "    query: str     # referred to as 'x' in the paper.\n",
    "    reasoning: str    # referred to as 'z' in the paper.   -> a joint distribution of this variable is what we're trying to obtain.\n",
    "    answer: str    # referred to as 'y' in the paper.\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class QueryAnswerPair:\n",
    "    q: str\n",
    "    a: str\n",
    "    \n",
    "def dataset_to_qapairs(df: pd.DataFrame) -> list[QueryAnswerPair]:\n",
    "    qa_pairs = list()\n",
    "    for row in df.itertuples():\n",
    "        qa_pair = QueryAnswerPair(q=row.sentence, a=row.clazz)\n",
    "        qa_pairs.append(qa_pair)\n",
    "    return qa_pairs\n",
    "\n",
    "def bootstrap(pairs: list[QueryAnswerPair]) -> tuple[list[CoTRecipe], list[CoTRecipe]]:\n",
    "    batch_answers = [p.a for p in pairs]\n",
    "    batch_queries = [p.q for p in pairs]\n",
    "    batch_messages = [bootstrap_prompt.format_prompt(query=q).to_messages() for q in batch_queries]\n",
    "    assert len(batch_messages) == len(batch_answers) == len(batch_queries), \"Mismatched number of queries and answers.\"\n",
    "    \n",
    "    # 1. generate the 'z' i.e. the reasoning via zeroshot.\n",
    "    print(\"+ Making calls to OpenAI. Please wait...\")\n",
    "    results = chat_model.generate(batch_messages)\n",
    "    print(\"+ Done.\")\n",
    "    \n",
    "    success: list[CoTRecipe] = list()\n",
    "    failed: tuple[list[CoTRecipe], str] = list()\n",
    "    for idx, (generation, query, true_answer) in enumerate(zip(results.generations, batch_queries, batch_answers)):\n",
    "        if len(generation) > 1: print(f\"+ > 1 generation? {idx=}\")\n",
    "        rapair = parse(generation[0].text)\n",
    "        recipe = CoTRecipe(query=query, reasoning=rapair.r, answer=rapair.a)\n",
    "        if rapair.a == true_answer:\n",
    "            success.append(recipe)\n",
    "        else:\n",
    "            failed.append((recipe, true_answer))\n",
    "    return success, failed \n",
    "\n",
    "\"Bootstrap logic defined. Please continue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b13bd-b81d-4e93-b487-48bc3f0607e4",
   "metadata": {},
   "source": [
    "## 5. Upload labelled dataset\n",
    "\n",
    "Please upload your excel dataset with the 'clazz' and 'sentence' columns.\n",
    "The 'clazz' column are your labels, these will be used to check against GPT generated answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3611d-e511-4084-a7e4-1b67c79a0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "finput, dataset = fileuploader(ext='.xlsx')\n",
    "finput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc97f2-4289-4594-9109-26a024a516f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert dataset.get('data'), \"Did you upload your dataset?\"\n",
    "\n",
    "df = pd.read_excel(dataset.get('data'))\n",
    "assert \"clazz\" in df.columns, \"Missing 'clazz' column in dataset.\"\n",
    "assert \"sentence\" in df.columns, \"Missing 'sentence' column in dataset.\"\n",
    "\n",
    "qa_pairs = dataset_to_qapairs(df)\n",
    "f\"Converted to {len(qa_pairs)} question answer pairs. Run the next cell and run the bootstrap process.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262f3c0-277e-49e1-a024-da4814156418",
   "metadata": {},
   "source": [
    "## 6. Bootstrap: Ask GPT to generate the CoT exemplars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4a439-e365-40af-9d6d-5ab5d6cec16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes, failed = bootstrap(qa_pairs)\n",
    "f\"Number of successes: {len(recipes)} fails: {len(failed)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b648e-23ca-4419-975b-7ffeadc434ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save recipes as .toml\n",
    "import toml\n",
    "import panel as pn\n",
    "from pathlib import Path\n",
    "data = dict()\n",
    "\n",
    "prev_data = toml.load(instrs.get('data'))\n",
    "prefix = prev_data.pop('PREFIX', None)\n",
    "if prefix is not None:\n",
    "    data['PREFIX'] = {'instruction': prefix.get('instruction') }\n",
    "\n",
    "for recipe in recipes:\n",
    "    if recipe.answer not in data.keys():\n",
    "        instruction = prev_data.get(recipe.answer, dict()).get('instruction', '')\n",
    "        data[recipe.answer] = {'examples': [{'query': recipe.query, 'steps': recipe.reasoning}], 'instruction': instruction}\n",
    "    else:\n",
    "        data.get(recipe.answer).get('examples').append({'query': recipe.query, 'steps': recipe.reasoning})\n",
    "\n",
    "path = Path('bootstrapped.toml')\n",
    "        \n",
    "with open(path, 'w') as h:\n",
    "    toml.dump(data, h)\n",
    "    \n",
    "pn.widgets.FileDownload(file=str(path), filename=path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a5238-f354-4996-aefe-7640f87f41a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Optional] Quick check of bootstrapped.toml that was generated.\n",
    "!cat bootstrapped.toml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
