{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d0b197-ff58-4ec2-96f2-000230ce4e46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline: Random Forest\n",
    "\n",
    "This notebook uses one of the two baseline classifiers: Random Forest to classify GEF biases based on sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848aa2fe-9e94-403a-9ec9-950640d58a6a",
   "metadata": {},
   "source": [
    "## 1. Upload your dataset\n",
    "\n",
    "Your dataset must be in excel format and must contain `sentence` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbc645-b268-423c-8e5d-430a3776c391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension(notifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a4e39-58ba-4cb8-9024-3911cf09ba2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import fileuploader \n",
    "\n",
    "uploaded = dict()\n",
    "sets = ['train', 'val', 'test']\n",
    "for set_ in sets:\n",
    "    finput, uploaded_data = fileuploader('.xlsx')\n",
    "    uploaded[set_] = dict()\n",
    "    uploaded[set_]['row'] = pn.Row(pn.pane.Str(f\"{set_} set:\".rjust(10)), finput)\n",
    "    uploaded[set_]['finput'] = finput\n",
    "    uploaded[set_]['upload'] = uploaded_data\n",
    "    \n",
    "pn.Column('# Upload datasets', *(uploaded[set_]['row'] for set_ in sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07f1d9-7dbd-4233-8b6e-20fb323387ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_uploads = all(uploaded[set_]['upload'].get('data', False) for set_ in uploaded.keys())\n",
    "if not has_uploads:\n",
    "    pn.state.notifications.error('Did you upload all 3 datasets?', duration=10_000)\n",
    "    raise Exception('Did you upload all 3 datasets?')\n",
    "import pandas as pd\n",
    "from atap_corpus.corpus import Corpus, Corpora\n",
    "import spacy\n",
    "\n",
    "dfs = []\n",
    "for set_ in sets:\n",
    "    df = pd.read_excel(uploaded[set_]['upload'].get('data'))\n",
    "    df['set'] = set_\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0)\n",
    "    \n",
    "corpus = Corpus.from_dataframe(df, col_doc='sentence')\n",
    "print(f\"Tokenising and building DTM for {corpus.name}...\")\n",
    "corpus.run_spacy(spacy.blank('en'))\n",
    "assert corpus.uses_spacy(), \"Corpus must be using spacy for spacy tokenisation.\"\n",
    "corpus.add_dtm_from_docs(lambda doc: list(t.text for t in doc), name='tokens')\n",
    "assert corpus.get_dtm('tokens') is not None, \"Corpus tokens DTM was not built.\"\n",
    "\"Successful. Please continue.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb437229-2d9e-4c1a-849b-d0b5bdeeeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = dict(DE=None, SE=None, NA=None, HD=None)\n",
    "for clazz in datasets.keys():\n",
    "    datasets[clazz] = dict()\n",
    "    neutral = corpus.s.filter_by_item(name=clazz, items=0)\n",
    "    biased = corpus.s.filter_by_item(name=clazz, items=1)\n",
    "    balanced_corp = biased.join(neutral.sample(len(biased), rand_stat=42))\n",
    "    \n",
    "    train = balanced_corp.s.filter_by_item(\"set\", [\"train\", \"val\"])\n",
    "    test = balanced_corp.s.filter_by_item(\"set\", \"test\")\n",
    "    X_train, y_train = np.asarray(train.dtms['tokens'].matrix.todense()), np.array(train[clazz].tolist())\n",
    "    X_test, y_test = np.asarray(test.dtms['tokens'].matrix.todense()), np.array(test[clazz].tolist())\n",
    "    \n",
    "    datasets[clazz]['X_train'] = X_train\n",
    "    datasets[clazz]['y_train'] = y_train\n",
    "    datasets[clazz]['X_test'] = X_test\n",
    "    datasets[clazz]['y_test'] = y_test\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9611013-6bda-4429-8688-2832fe8b4852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 100\n",
    "for clazz, dataset in datasets.items():\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    clf.fit(dataset['X_train'], dataset['y_train'])\n",
    "    y_preds = clf.predict(dataset['X_test'])\n",
    "    dataset['rf'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d70cd-4468-4b45-8457-72772c7f0d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tmpd = Path(tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f4470-914c-4578-9ce3-eb96723b89d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from typing import IO\n",
    "import io\n",
    "\n",
    "def evaluate(y_pred: np.ndarray, y_true: np.ndarray, file: IO, labels=None, **kwargs):\n",
    "    assert y_pred.shape == y_true.shape, \"Mismatched shape between y_pred and y_true.\"\n",
    "    assert file.writable(), \"File is not writable.\"\n",
    "    report = classification_report(y_pred=y_pred, y_true=y_true, output_dict=False, labels=labels, **kwargs)\n",
    "    file.write(report)\n",
    "    \n",
    "\n",
    "classifier = \"rf\"\n",
    "file = io.TextIOWrapper(io.BufferedWriter(io.FileIO(tmpd.joinpath(f\"{classifier}.txt\"), mode='w')), encoding='utf-8')\n",
    "s = io.StringIO()\n",
    "for clazz, dataset in datasets.items():\n",
    "    file.write(\"===\" + clazz + \"===\\n\")\n",
    "    s.write(\"===\" + clazz + \"===\\n\")\n",
    "    evaluate(datasets[clazz][classifier], datasets[clazz]['y_test'], file=file)\n",
    "    evaluate(datasets[clazz][classifier], datasets[clazz]['y_test'], file=s)\n",
    "file.close()\n",
    "s.seek(0)\n",
    "print(s.read()); s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe05ccf-3fac-4c9a-a547-36f41a0f035c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(y_pred: np.ndarray, y_true: np.ndarray, **kwargs):\n",
    "    assert y_pred.shape == y_true.shape, \"Mismatched shape between y_pred and y_true.\"\n",
    "    report = classification_report(y_pred=y_pred, y_true=y_true, output_dict=True, **kwargs)\n",
    "    return report\n",
    "\n",
    "r_dfs = list()\n",
    "for clazz in datasets.keys():\n",
    "    report = evaluate(datasets[clazz][classifier], datasets[clazz]['y_test'])\n",
    "    r_df = pd.DataFrame.from_dict(report).T.loc[['0', '1'], ['precision', 'recall', 'f1-score']]\n",
    "    r_dfs.append(r_df)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Select a colormap\n",
    "cmap = cm.get_cmap('tab20c')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12, 6))\n",
    "categories = list(datasets.keys())\n",
    "colors = cmap(np.linspace(0, 1, len(categories)))\n",
    "              \n",
    "values = []\n",
    "for r_df in r_dfs:\n",
    "    pre = r_df.loc['1', 'precision']\n",
    "    rec = r_df.loc['1', 'recall']\n",
    "    f1 = r_df.loc['1', 'f1-score']\n",
    "    values.append([pre, rec, f1])\n",
    "values = np.array(values)\n",
    "\n",
    "for i, metric in enumerate(['precision', 'recall', 'f1-score']):\n",
    "    plt.scatter(categories, values[:, i], color=colors[i], label=metric)\n",
    "\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel('Bias', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(tmpd.joinpath('plot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267d566-3cbf-4286-a6c6-e9e66805e48e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import panel as pn\n",
    "\n",
    "now = datetime.now().strftime(format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "zfname = Path(f'{now}-{classifier}.zip')\n",
    "file_names = list(tmpd.rglob(\"*\"))\n",
    "file_names += [u['upload']['data'] for u in uploaded.values()]\n",
    "with zipfile.ZipFile(zfname, 'w') as zipf:\n",
    "    for file_name in file_names:\n",
    "        zipf.write(file_name, arcname=os.path.basename(file_name))\n",
    "print(f\"Saved as {zfname}.\\nClick below to download.\")\n",
    "\n",
    "# download link for the zip.\n",
    "pn.widgets.FileDownload(file=str(zfname), filename=zfname.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
