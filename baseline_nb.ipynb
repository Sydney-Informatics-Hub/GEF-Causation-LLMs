{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb5a2f5-2615-4961-9add-e8950d8f4c1a",
   "metadata": {},
   "source": [
    "# Baseline: Naive Bayes\n",
    "\n",
    "This notebook uses one of the two baseline classifiers: Naive Bayes to classify GEF biases based on sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a689d0a-1936-4adb-aa2d-91f4baf62a1e",
   "metadata": {},
   "source": [
    "## 1. Upload your dataset\n",
    "\n",
    "Your dataset must be in excel format and must contain `sentence` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eca6fc-d930-47fd-9d77-ee6979d2685e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension(notifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c5b38-5bf5-4621-acff-fea92e58fc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import fileuploader \n",
    "\n",
    "uploaded = dict()\n",
    "sets = ['train', 'val', 'test']\n",
    "for set_ in sets:\n",
    "    finput, uploaded_data = fileuploader('.xlsx')\n",
    "    uploaded[set_] = dict()\n",
    "    uploaded[set_]['row'] = pn.Row(pn.pane.Str(f\"{set_} set:\".rjust(10)), finput)\n",
    "    uploaded[set_]['finput'] = finput\n",
    "    uploaded[set_]['upload'] = uploaded_data\n",
    "    \n",
    "pn.Column('# Upload datasets', *(uploaded[set_]['row'] for set_ in sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c573ac-5829-4c0d-bfc8-feeb444e7259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_uploads = all(uploaded[set_]['upload'].get('data', False) for set_ in uploaded.keys())\n",
    "if not has_uploads:\n",
    "    pn.state.notifications.error('Did you upload all 3 datasets?', duration=10_000)\n",
    "    raise Exception('Did you upload all 3 datasets?')\n",
    "import pandas as pd\n",
    "from atap_corpus.corpus import Corpus, Corpora\n",
    "import spacy\n",
    "\n",
    "dfs = []\n",
    "for set_ in sets:\n",
    "    df = pd.read_excel(uploaded[set_]['upload'].get('data'))\n",
    "    df['set'] = set_\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0)\n",
    "    \n",
    "corpus = Corpus.from_dataframe(df, col_doc='sentence')\n",
    "print(f\"Tokenising and building DTM for {corpus.name}...\")\n",
    "corpus.run_spacy(spacy.blank('en'))\n",
    "assert corpus.uses_spacy(), \"Corpus must be using spacy for spacy tokenisation.\"\n",
    "corpus.add_dtm_from_docs(lambda doc: list(t.text for t in doc), name='tokens')\n",
    "assert corpus.get_dtm('tokens') is not None, \"Corpus tokens DTM was not built.\"\n",
    "\"Successful. Please continue.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feacf083-b501-4eed-91db-f7a0bb7ac3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = dict(DE=None, SE=None, NA=None, HD=None)\n",
    "for clazz in datasets.keys():\n",
    "    datasets[clazz] = dict()\n",
    "    neutral = corpus.s.filter_by_item(name=clazz, items=0)\n",
    "    biased = corpus.s.filter_by_item(name=clazz, items=1)\n",
    "    balanced_corp = biased.join(neutral.sample(len(biased), rand_stat=42))\n",
    "    \n",
    "    train = balanced_corp.s.filter_by_item(\"set\", [\"train\", \"val\"])\n",
    "    test = balanced_corp.s.filter_by_item(\"set\", \"test\")\n",
    "    X_train, y_train = np.asarray(train.dtms['tokens'].matrix.todense()), np.array(train[clazz].tolist())\n",
    "    X_test, y_test = np.asarray(test.dtms['tokens'].matrix.todense()), np.array(test[clazz].tolist())\n",
    "    \n",
    "    datasets[clazz]['X_train'] = X_train\n",
    "    datasets[clazz]['y_train'] = y_train\n",
    "    datasets[clazz]['X_test'] = X_test\n",
    "    datasets[clazz]['y_test'] = y_test\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac2bcb-df73-4a6d-8cb2-7fcdc5980946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "for clazz, dataset in datasets.items():\n",
    "    mnb = MultinomialNB()   # each feature is multinomial since its frequencies.\n",
    "    mnb.fit(dataset['X_train'], dataset['y_train'])\n",
    "    y_preds = mnb.predict(dataset['X_test'])\n",
    "    dataset['nb'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf0935-e410-40da-a177-1df406a521f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from typing import IO\n",
    "\n",
    "def evaluate(y_pred: np.ndarray, y_true: np.ndarray, file: IO, labels=None, **kwargs):\n",
    "    assert y_pred.shape == y_true.shape, \"Mismatched shape between y_pred and y_true.\"\n",
    "    assert file.writable(), \"File is not writable.\"\n",
    "    report = classification_report(y_pred=y_pred, y_true=y_true, output_dict=False, labels=labels, **kwargs)\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20729d3-5b0b-4b1b-97bb-3617d46ded50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "classifier = \"nb\"\n",
    "s = io.StringIO()\n",
    "for clazz, dataset in datasets.items():\n",
    "    s.write(\"===\" + clazz + \"===\\n\")\n",
    "    evaluate(datasets[clazz][classifier], datasets[clazz]['y_test'], file=s)\n",
    "s.seek(0)\n",
    "print(s.read()); s.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77323b6a-252c-42c2-a79e-28b362dff1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
