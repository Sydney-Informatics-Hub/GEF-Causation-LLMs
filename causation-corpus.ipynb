{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d65e207-d2d6-4e2b-a2ea-38887a5018e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Causation Corpus classification \n",
    "#### Chain of Thoughts Self Consistency\n",
    "\n",
    "This notebook uses the chain-of-thoughts self consistency prompting technique to classify sentences via LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4dd3b-9b8e-4c81-867c-a804b093598e",
   "metadata": {},
   "source": [
    "## OpenAI Privacy Policy\n",
    "This notebook uses OpenAI's API, meaning that your data will be sent to the OpenAI servers.\n",
    "\n",
    "For concerns about how your data will be handled, please read through the Privacy Policy [here](https://openai.com/policies/api-data-usage-policies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff169e-6c32-427e-b960-68760725b9e6",
   "metadata": {},
   "source": [
    "## 1. Supply API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392cfaac-b5b5-4177-a368-274de23ea674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import openai_apikey_input\n",
    "\n",
    "openai_apikey_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e0f70-4a5e-410f-99b1-06b6b1d92a43",
   "metadata": {},
   "source": [
    "## 2. Upload Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a311e3-947a-445b-8c3c-aff9ec89f56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import fileuploader \n",
    "\n",
    "finput, exemplars = fileuploader('.toml')\n",
    "finput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d08512-0520-4924-ac4a-1545b8dc6742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoding issue - 27.Sep.23 - this strips away the whitespace/end-of-line character at the end of each line.\n",
    "# it's okay to always run this cell with or without the encoding issue.\n",
    "!sed 's/\" $/\"/g' \"{exemplars.get('data').absolute()}\" > \"{exemplars.get('data').absolute()}.formatted\"\n",
    "!mv \"{exemplars.get('data').absolute()}.formatted\" \"{exemplars.get('data').absolute()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ef2af-a53a-46ff-8a60-4b4cdff4652b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert exemplars.get('data'), \"Did you upload your CoT examples in the previous cell?\"\n",
    "\n",
    "from llm_experiments import CoT\n",
    "\n",
    "cot = CoT.from_toml(exemplars.get('data'))\n",
    "cot.shuffle_examples()                                         # improves result\n",
    "f\"These CoT example class distributions: {cot.class_dist()}\"   # try to keep this balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab4dc9-508b-4ac3-a266-4629db57ac75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Optional] - randomly sample X CoT examples to reduce input tokens.\n",
    "cot.sample(method='random', n=len(cot.examples))\n",
    "cot.class_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa8fb2-93c7-4567-8422-95805b1df493",
   "metadata": {},
   "source": [
    "## 3. Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205a77c-b3f8-43d0-9be8-d1b0d56395a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llm_experiments import SamplingScheme\n",
    "\n",
    "sampling_scheme = SamplingScheme(top_p=0.8, temperature=1, presence_penalty=0.0)\n",
    "n_completions = 3\n",
    "\n",
    "assert n_completions > 1, \"For the model to generate > 1 possibilities needed for self-consistency, n_completions must be > 1.\"\n",
    "assert sampling_scheme.temperature > 0, \"For the model to generate > 1 possibilities needed for self-consistency, temperature must be > 0.\"\n",
    "sampling_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1a3e3-fc44-4806-814a-0ed5208a2e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llm_experiments import CoTSC\n",
    "\n",
    "cotsc = CoTSC.from_cot(model='gpt-3.5-turbo',  # for a larger context window (from 4k -> 16k tokens) replace with 'gpt-3.5-turbo-16k'\n",
    "                       cot=cot,\n",
    "                       sampling_scheme=sampling_scheme,\n",
    "                       n_completions=n_completions)\n",
    "f\"{cotsc.model}   'temperature': {cotsc.llm.temperature}, {str(cotsc.llm.model_kwargs).lstrip('{').rstrip('}')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1ceb5-bb06-46a1-b4e4-974990c05fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt, num_tokens = cotsc.dryrun(query=\"Canberra immunologist Carola Vinuesa who discovered a gene responsible for the autoimmune diseases lupus and diabetes.\")\n",
    "f\"This is a test run. Number of tokens in the above prompt: {num_tokens}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed5cb9-1f06-4515-9210-5319d3e3848e",
   "metadata": {},
   "source": [
    "## 4. Upload your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b9dc8-490e-48d1-a314-408ce3f24e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import fileuploader\n",
    "\n",
    "finput, dataset = fileuploader('.xlsx')\n",
    "finput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e1c92-6ec3-4fa7-a82a-4f3fd5c65366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "assert dataset.get('data'), \"Did you upload your dataset?\"\n",
    "df = pd.read_excel(dataset.get('data'))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185ff76-8ea1-42e5-adfc-037e9356c858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 'sentence' in df.columns, \"Missing 'sentence' column in your dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0be6f-ad66-41ee-89e3-2ce27a5f447b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f\"Number of examples found: {len(df)}. Please continue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78963ce7-29aa-482b-a2b9-1f65f78dc619",
   "metadata": {},
   "source": [
    "## 5. Set up TikDollar (default cost_threshold is set to $1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe665745-e1f5-4fd3-bcc8-b07a2106ab28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llm_experiments.utils import TikDollar as td\n",
    "\n",
    "# ⚠️ Caveat: When you rerun this cell, tikdollar is reset to 0!\n",
    "tikdollar = td.track(cotsc, cotsc._tikdollar_run, cost_threshold=1.0, raise_err=True, verbose=False)\n",
    "tikdollar  # starts out with zero cost accumulated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df2f9d-c597-4c1b-af91-3c29e86a8aec",
   "metadata": {},
   "source": [
    "## 6. Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e65754-2729-4106-bf05-7e61fe587db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from llm_experiments.cot import CoT, CoTSC\n",
    "from llm_experiments.cot.cot import CoTDataLeakException\n",
    "from llm_experiments.utils.tikdollar import CostThresholdReachedException\n",
    "\n",
    "checkpointing = 200  # save after every {checkpointing} queries.\n",
    "print(f\"Results will be saved every {checkpointing} queries.\")\n",
    "\n",
    "VOTE_STR = 'vote[{clazz}]'\n",
    "REASON_STR = 'reason[{clazz}]'\n",
    "\n",
    "# setup dataframe.\n",
    "results_df = df.loc[:, 'sentence'].copy(deep=True)\n",
    "results_df = pd.DataFrame(results_df, columns=['sentence'])\n",
    "for clazz in cotsc.classes:\n",
    "    results_df[VOTE_STR.format(clazz=clazz)] = 0\n",
    "    results_df[REASON_STR.format(clazz=clazz)] = ''\n",
    "results_df = results_df.sort_index(axis=1, ascending=False)\n",
    "results_df = results_df[['sentence'] + [col for col in results_df.columns if col != 'sentence']]\n",
    "results_df['raw_output'] = ''\n",
    "\n",
    "dleak_counter = 0\n",
    "for i, sent in tqdm(enumerate(results_df.loc[:, 'sentence']), total=len(results_df)):\n",
    "    try:\n",
    "        results = cotsc.run(query=sent)\n",
    "        for clazz, clz_results in results.items():\n",
    "            results_df.loc[i, VOTE_STR.format(clazz=clazz)] = clz_results.get('votes')\n",
    "            results_df.loc[i, REASON_STR.format(clazz=clazz)] = \"\\n\".join(clz_results.get('steps'))\n",
    "            results_df.loc[i, 'raw_output'] = \"\\n\".join(clz_results.get('completions'))\n",
    "    except CoTDataLeakException as cotdle:\n",
    "        # todo: make these prints alerts.\n",
    "        print(cotdle)\n",
    "        print(\"Data leak detected. Skipped.\")\n",
    "        dleak_counter += 1\n",
    "        continue\n",
    "    except CostThresholdReachedException as ctre:\n",
    "        print(ctre)\n",
    "        print(f\"Number of queries sent: {i}.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    if checkpointing and (i + 1) % checkpointing == 0:\n",
    "        path = f'./cotsc-outputs-checkpoint-{i + 1}.xlsx'\n",
    "        results_df.to_excel(path)\n",
    "        print(f\"Checkpointed at {i + 1} queries processed. Checkpoint file: {path}.\")\n",
    "        \n",
    "print(f\"Number of examples leaked: {dleak_counter}. Please continue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c411588-53d3-43e0-b93f-1b59813424c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some postprocessing.\n",
    "import re\n",
    "results_df['majority'] = results_df.filter(regex=r'vote*').idxmax(axis=1).apply(lambda col_name: re.search(r'\\[(.*?)\\]', col_name).group(1))\n",
    "results_df = results_df[['sentence', 'majority'] + [col for col in results_df.columns if col not in ('sentence', 'majority')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d9d40-e41a-4046-ac64-5627a8708de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "print(\"Please continue.\")\n",
    "\n",
    "if input(\"Display results? (y/n): \").lower() == 'y':\n",
    "    display(HTML(results_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed1622b-09f9-47fd-a070-07271b84d24c",
   "metadata": {},
   "source": [
    "## 7. Download - run the following cells in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ddc7e-ceb5-45a0-9ea6-ac0d6d8ef6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import srsly\n",
    "\n",
    "now = datetime.now().strftime(format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_dir = Path(f\"./.cotsc-corpus-output-{now}\")\n",
    "output_dir.mkdir(exist_ok=False)\n",
    "\n",
    "# 1. cotsc-output.xlsx\n",
    "results_df.to_excel(output_dir.joinpath('cotsc-output.xlsx'))\n",
    "# 2. model config\n",
    "path = output_dir.joinpath('cotsc-config.json')\n",
    "cotsc_config = {\n",
    "    'sampling_scheme': sampling_scheme.openai(),\n",
    "    'n_completions': cotsc.n_completions,\n",
    "    'model': cotsc.model,\n",
    "    'classes': cotsc.classes,\n",
    "}\n",
    "srsly.write_json(path, cotsc_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cec41-594b-4ec5-ad8e-5916a4835c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. dataset\n",
    "# 4. toml\n",
    "\n",
    "file_names = [exemplars['data'], dataset['data']]  # toml & dataset\n",
    "file_names += list(output_dir.glob(\"*\"))\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43611781-0298-4ca3-8bd3-e7c3e90ccdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import panel as pn\n",
    "\n",
    "zfname = Path(f'{now}-cotsc-corpus.zip')\n",
    "with zipfile.ZipFile(zfname, 'w') as zipf:\n",
    "    for file_name in file_names:\n",
    "        zipf.write(file_name, arcname=os.path.basename(file_name))\n",
    "print(f\"Saved as {zfname}.\\nClick below to download.\")\n",
    "\n",
    "# download link for the zip.\n",
    "pn.widgets.FileDownload(file=str(zfname), filename=zfname.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b43a58-e852-46cf-968f-e055cf3af126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
