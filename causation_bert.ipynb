{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02250dfa-ae78-4f79-ad56-3eb25bba29bd",
   "metadata": {},
   "source": [
    "# BERT\n",
    "This notebook uses BERT for the bias classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717a7d9-4860-412a-95bd-588b94d2decd",
   "metadata": {},
   "source": [
    "## 1. Upload your dataset\n",
    "\n",
    "Your dataset must be in excel format and must contain `sentence` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eca6fc-d930-47fd-9d77-ee6979d2685e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension(notifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c5b38-5bf5-4621-acff-fea92e58fc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from causation.utils import fileuploader \n",
    "\n",
    "uploaded = dict()\n",
    "sets = ['train', 'val', 'test']\n",
    "for set_ in sets:\n",
    "    finput, uploaded_data = fileuploader('.xlsx')\n",
    "    uploaded[set_] = dict()\n",
    "    uploaded[set_]['row'] = pn.Row(pn.pane.Str(f\"{set_} set:\".rjust(10)), finput)\n",
    "    uploaded[set_]['finput'] = finput\n",
    "    uploaded[set_]['upload'] = uploaded_data\n",
    "    \n",
    "pn.Column('# Upload datasets', *(uploaded[set_]['row'] for set_ in sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c573ac-5829-4c0d-bfc8-feeb444e7259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "has_uploads = all(uploaded[set_]['upload'].get('data', False) for set_ in uploaded.keys())\n",
    "if not has_uploads:\n",
    "    pn.state.notifications.error('Did you upload all 3 datasets?', duration=10_000)\n",
    "    raise Exception('Did you upload all 3 datasets?')\n",
    "import pandas as pd\n",
    "from atap_corpus.corpus import Corpus, Corpora\n",
    "import spacy\n",
    "\n",
    "corpora = Corpora([\n",
    "    Corpus.from_dataframe(pd.read_excel(uploaded[set_]['upload'].get('data')), col_doc='sentence', name=set_) for set_ in sets\n",
    "])\n",
    "\n",
    "[(c.name, len(c)) for c in corpora.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4164fb5-f786-4421-8562-61e960c51a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4c9ff-febb-48f6-8786-8f3eaeb9011e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50769331-ee32-4301-8221-27bf971c9b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "import numpy as np\n",
    "\n",
    "class GeneDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def create_gene_datasets(bert_model: str, train: tuple, test: tuple, val: tuple = None) -> dict[str, GeneDataset]:\n",
    "    \"\"\" Transform text dataset to bert encodings dataset.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "    if 'uncased' in bert_model: assert tokenizer.do_lower_case\n",
    "\n",
    "    assert isinstance(train, tuple) and len(train) == 2, \"Invalid data structure, use split_dataset to get tuples.\"\n",
    "    assert isinstance(train[0], list) and isinstance(train[1],\n",
    "                                                     np.ndarray), \"Invalid data structure, use split_dataset to get tuples.\"\n",
    "\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "\n",
    "    train_encodings: BatchEncoding = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "    test_encodings: BatchEncoding = tokenizer(X_test, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    datasets = {\n",
    "        'train': GeneDataset(train_encodings, y_train),\n",
    "        'test': GeneDataset(test_encodings, y_test)\n",
    "    }\n",
    "\n",
    "    if val:\n",
    "        X_val, y_val = val\n",
    "        val_encodings: BatchEncoding = tokenizer(X_val, truncation=True, padding=True, max_length=512)\n",
    "        datasets.update({'val': GeneDataset(val_encodings, y_val)})\n",
    "    return datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203a10e-9879-454f-a623-4353aa2adb5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Define evaluation metric\n",
    "metric = evaluate.load('f1')\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "class GeneTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss\n",
    "        loss_fct = nn.CrossEntropyLoss(reduction='mean')\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67fa4a-8043-4557-a903-01f8cc6be964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import transformers\n",
    "from transformers import TrainingArguments, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "transformers.logging.set_verbosity(transformers.logging.ERROR)   # stop from_pretrained calls to output loading from config, weights... logs. But will load errors.\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.round(torch.sigmoid(torch.tensor(logits)))\n",
    "    predictions = torch.argmax(predictions, axis=1)\n",
    "    return {'jaccard': jaccard_score(labels,predictions, average='weighted')}\n",
    "\n",
    "trial = f\"trial_{datetime.now().strftime('%d-%m-%YT%H:%M:%S')}\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL,\n",
    "                                                       problem_type='single_label_classification').to(device)\n",
    "args = TrainingArguments(\n",
    "    output_dir='./.output/'+trial,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    eval_steps=20,\n",
    "    save_steps=20,\n",
    "    num_train_epochs=40,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    "    log_level='error',\n",
    "    use_mps_device= device == 'mps',\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    optim='adamw_hf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02e6fa-a2de-4dd4-8821-c47407ab84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = corpora.items()[0]\n",
    "test = corpora.items()[-1]\n",
    "val = corpora.items()[1]\n",
    "\n",
    "results = dict()\n",
    "classes = ['DE', 'SE', 'NA', 'HD']\n",
    "for clz in classes:\n",
    "    neutral = train.s.filter_by_item(name=clz, items=0)\n",
    "    biased = train.s.filter_by_item(name=clz, items=1)\n",
    "    balanced_train = biased.join(neutral.sample(len(biased), rand_stat=42))\n",
    "    X_train = balanced_train.docs().tolist()\n",
    "    y_train = np.array(balanced_train[clz].tolist())\n",
    "    \n",
    "    X_test = test.docs().tolist()\n",
    "    y_test = np.array(test[clz].tolist())\n",
    "    \n",
    "    X_val = val.docs().tolist()\n",
    "    y_val = np.array(val[clz].tolist())\n",
    "    \n",
    "    datasets = create_gene_datasets(bert_model=MODEL, train=(X_train, y_train), test=(X_test, y_test), val=(X_val, y_val))\n",
    "\n",
    "    trainer = GeneTrainer(model=model, args=args, compute_metrics=compute_metrics,\n",
    "                         train_dataset=datasets.get('train'), eval_dataset=datasets.get('val'),\n",
    "                         callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.0)])\n",
    "    trainer.train()\n",
    "    outputs = trainer.predict(datasets.get('test'))\n",
    "    preds, labels = outputs.predictions, outputs.label_ids\n",
    "    pred = torch.argmax(torch.round(torch.sigmoid(torch.tensor(preds))), axis=1)\n",
    "    results[clz] = dict()\n",
    "    results[clz]['labels'] = labels\n",
    "    results[clz]['preds'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950c357-25a7-49a0-b7f3-5fe1bf0a218e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tmpd = Path(tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06621382-028d-4812-a59d-55ab3535b0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from typing import IO\n",
    "import io\n",
    "\n",
    "def evaluate(y_pred: np.ndarray, y_true: np.ndarray, file: IO, labels=None, **kwargs):\n",
    "    assert y_pred.shape == y_true.shape, \"Mismatched shape between y_pred and y_true.\"\n",
    "    assert file.writable(), \"File is not writable.\"\n",
    "    report = classification_report(y_pred=y_pred, y_true=y_true, output_dict=False, labels=labels, **kwargs)\n",
    "    file.write(report)\n",
    "    \n",
    "classifier = \"BERT\"\n",
    "file = io.TextIOWrapper(io.BufferedWriter(io.FileIO(tmpd.joinpath(f\"{classifier}.txt\"), mode='w')), encoding='utf-8')\n",
    "s = io.StringIO()\n",
    "for clazz, res in results.items():\n",
    "    file.write(\"===\" + clazz + \"===\\n\")\n",
    "    s.write(\"===\" + clazz + \"===\\n\")\n",
    "    evaluate(res['preds'], res['labels'], file=file)\n",
    "    evaluate(res['preds'], res['labels'], file=s)\n",
    "file.close()\n",
    "s.seek(0)\n",
    "print(s.read()); s.close()\n",
    "print(classification_report(y_pred=pred, y_true=labels, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc181a-339a-4b76-9f53-61c611c28e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(y_pred: np.ndarray, y_true: np.ndarray, **kwargs):\n",
    "    assert y_pred.shape == y_true.shape, \"Mismatched shape between y_pred and y_true.\"\n",
    "    report = classification_report(y_pred=y_pred, y_true=y_true, output_dict=True, **kwargs)\n",
    "    return report\n",
    "\n",
    "r_dfs = list()\n",
    "for clazz, res in results.items():\n",
    "    report = evaluate(res['preds'], res['labels'])\n",
    "    r_df = pd.DataFrame.from_dict(report).T.loc[['0', '1'], ['precision', 'recall', 'f1-score']]\n",
    "    r_dfs.append(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6b64f-edd3-482b-bad2-4033e2343ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Select a colormap\n",
    "cmap = cm.get_cmap('tab20c')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12, 6))\n",
    "categories = list(results.keys())\n",
    "colors = cmap(np.linspace(0, 1, len(categories)))\n",
    "              \n",
    "values = []\n",
    "for r_df in r_dfs:\n",
    "    pre = r_df.loc['1', 'precision']\n",
    "    rec = r_df.loc['1', 'recall']\n",
    "    f1 = r_df.loc['1', 'f1-score']\n",
    "    values.append([pre, rec, f1])\n",
    "values = np.array(values)\n",
    "\n",
    "for i, metric in enumerate(['precision', 'recall', 'f1-score']):\n",
    "    plt.scatter(categories, values[:, i], color=colors[i], label=metric)\n",
    "\n",
    "plt.title(classifier)\n",
    "plt.xlabel('Bias', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(tmpd.joinpath('plot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb1375-9450-49f2-a656-30db50316b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import panel as pn\n",
    "\n",
    "now = datetime.now().strftime(format=\"%Y-%m-%d_%H-%M-%S\")\n",
    "zfname = Path(f'{now}-{classifier}.zip')\n",
    "file_names = list(tmpd.rglob(\"*\"))\n",
    "file_names += [u['upload']['data'] for u in uploaded.values()]\n",
    "with zipfile.ZipFile(zfname, 'w') as zipf:\n",
    "    for file_name in file_names:\n",
    "        zipf.write(file_name, arcname=os.path.basename(file_name))\n",
    "print(f\"Saved as {zfname}.\\nClick below to download.\")\n",
    "\n",
    "# download link for the zip.\n",
    "pn.widgets.FileDownload(file=str(zfname), filename=zfname.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1eae4-4e45-4832-b560-71ca84ed7352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
